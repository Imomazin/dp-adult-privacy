{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDF42jlCYewvYlAy5Lb19X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imomazin/dp-adult-privacy/blob/main/DP_Adult_Membership_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdkqJIY2qsZs",
        "outputId": "18383d89-533a-47e4-8bce-c3493598dbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dp-adult-privacy'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 25 (delta 3), reused 19 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 28.38 KiB | 880.00 KiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/dp-adult-privacy\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.0+cpu)\n",
            "Collecting opacus>=1.4.0 (from -r requirements.txt (line 5))\n",
            "  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus>=1.4.0->-r requirements.txt (line 5)) (1.16.3)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus>=1.4.0->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 10)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 2)) (3.0.3)\n",
            "Downloading opacus-1.5.4-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opacus\n",
            "Successfully installed opacus-1.5.4\n",
            "/content/dp-adult-privacy/src\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Imomazin/dp-adult-privacy.git\n",
        "%cd dp-adult-privacy\n",
        "!pip install -r requirements.txt\n",
        "%cd src"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_baseline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnAm0U5Mmgdh",
        "outputId": "f20168d3-dc17-4b4d-9264-fb2cf6d4676d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Loading Data ---\n",
            "Downloading training data to data/adult.data...\n",
            "Download complete.\n",
            "Downloading test data to data/adult.test...\n",
            "Download complete.\n",
            "Training samples after dropping NA: 30162\n",
            "Test samples after dropping NA: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Training ---\n",
            "Epoch 1/20 | Train Loss: 0.4007 | Val Loss: 0.3229 | Val Acc: 0.8505\n",
            "Epoch 2/20 | Train Loss: 0.3173 | Val Loss: 0.3179 | Val Acc: 0.8489\n",
            "Epoch 3/20 | Train Loss: 0.3117 | Val Loss: 0.3134 | Val Acc: 0.8542\n",
            "Epoch 4/20 | Train Loss: 0.3099 | Val Loss: 0.3124 | Val Acc: 0.8575\n",
            "Epoch 5/20 | Train Loss: 0.3072 | Val Loss: 0.3107 | Val Acc: 0.8535\n",
            "Epoch 6/20 | Train Loss: 0.3079 | Val Loss: 0.3144 | Val Acc: 0.8575\n",
            "Epoch 7/20 | Train Loss: 0.3017 | Val Loss: 0.3097 | Val Acc: 0.8591\n",
            "Epoch 8/20 | Train Loss: 0.2991 | Val Loss: 0.3112 | Val Acc: 0.8565\n",
            "Epoch 9/20 | Train Loss: 0.2991 | Val Loss: 0.3126 | Val Acc: 0.8535\n",
            "Epoch 10/20 | Train Loss: 0.2968 | Val Loss: 0.3120 | Val Acc: 0.8598\n",
            "Epoch 11/20 | Train Loss: 0.2932 | Val Loss: 0.3124 | Val Acc: 0.8578\n",
            "Epoch 12/20 | Train Loss: 0.2916 | Val Loss: 0.3094 | Val Acc: 0.8608\n",
            "Epoch 13/20 | Train Loss: 0.2929 | Val Loss: 0.3133 | Val Acc: 0.8585\n",
            "Epoch 14/20 | Train Loss: 0.2905 | Val Loss: 0.3197 | Val Acc: 0.8542\n",
            "Epoch 15/20 | Train Loss: 0.2891 | Val Loss: 0.3127 | Val Acc: 0.8605\n",
            "Epoch 16/20 | Train Loss: 0.2825 | Val Loss: 0.3158 | Val Acc: 0.8578\n",
            "Epoch 17/20 | Train Loss: 0.2833 | Val Loss: 0.3177 | Val Acc: 0.8571\n",
            "Epoch 18/20 | Train Loss: 0.2815 | Val Loss: 0.3224 | Val Acc: 0.8479\n",
            "Epoch 19/20 | Train Loss: 0.2828 | Val Loss: 0.3224 | Val Acc: 0.8495\n",
            "Epoch 20/20 | Train Loss: 0.2751 | Val Loss: 0.3205 | Val Acc: 0.8598\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3336 | Test Accuracy: 0.8487\n",
            "Model saved to checkpoints/baseline_final.pt\n",
            "\n",
            "--- Training Complete ---\n",
            "Best validation accuracy: 0.8608\n",
            "Final test accuracy: 0.8487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_dp.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAE7TxO8nAsD",
        "outputId": "f0fa672c-7d2a-447f-c513-145323c325a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Loading Data ---\n",
            "Training data already exists at data/adult.data\n",
            "Test data already exists at data/adult.test\n",
            "Training samples after dropping NA: 30162\n",
            "Test samples after dropping NA: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 8.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.6363\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.5647 | Val Loss: 0.4745 | Val Acc: 0.7511 | ε: 3.12\n",
            "Epoch 2/20 | Train Loss: 0.4414 | Val Loss: 0.4134 | Val Acc: 0.8386 | ε: 3.63\n",
            "Epoch 3/20 | Train Loss: 0.4603 | Val Loss: 0.4677 | Val Acc: 0.8439 | ε: 4.03\n",
            "Epoch 4/20 | Train Loss: 0.4706 | Val Loss: 0.4568 | Val Acc: 0.8492 | ε: 4.38\n",
            "Epoch 5/20 | Train Loss: 0.4568 | Val Loss: 0.4626 | Val Acc: 0.8502 | ε: 4.69\n",
            "Epoch 6/20 | Train Loss: 0.4710 | Val Loss: 0.4551 | Val Acc: 0.8472 | ε: 4.98\n",
            "Epoch 7/20 | Train Loss: 0.4740 | Val Loss: 0.4672 | Val Acc: 0.8528 | ε: 5.25\n",
            "Epoch 8/20 | Train Loss: 0.4625 | Val Loss: 0.4713 | Val Acc: 0.8528 | ε: 5.51\n",
            "Epoch 9/20 | Train Loss: 0.4641 | Val Loss: 0.4644 | Val Acc: 0.8542 | ε: 5.75\n",
            "Epoch 10/20 | Train Loss: 0.4792 | Val Loss: 0.4589 | Val Acc: 0.8522 | ε: 5.99\n",
            "Epoch 11/20 | Train Loss: 0.4685 | Val Loss: 0.4642 | Val Acc: 0.8548 | ε: 6.22\n",
            "Epoch 12/20 | Train Loss: 0.4729 | Val Loss: 0.4680 | Val Acc: 0.8552 | ε: 6.43\n",
            "Epoch 13/20 | Train Loss: 0.4651 | Val Loss: 0.4662 | Val Acc: 0.8552 | ε: 6.65\n",
            "Epoch 14/20 | Train Loss: 0.4680 | Val Loss: 0.4688 | Val Acc: 0.8575 | ε: 6.85\n",
            "Epoch 15/20 | Train Loss: 0.4682 | Val Loss: 0.4635 | Val Acc: 0.8555 | ε: 7.06\n",
            "Epoch 16/20 | Train Loss: 0.4711 | Val Loss: 0.4700 | Val Acc: 0.8542 | ε: 7.25\n",
            "Epoch 17/20 | Train Loss: 0.4611 | Val Loss: 0.4671 | Val Acc: 0.8561 | ε: 7.44\n",
            "Epoch 18/20 | Train Loss: 0.4669 | Val Loss: 0.4672 | Val Acc: 0.8552 | ε: 7.63\n",
            "Epoch 19/20 | Train Loss: 0.4800 | Val Loss: 0.4592 | Val Acc: 0.8578 | ε: 7.82\n",
            "Epoch 20/20 | Train Loss: 0.4666 | Val Loss: 0.4609 | Val Acc: 0.8568 | ε: 8.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (8.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4700 | Test Accuracy: 0.8521\n",
            "Model saved to checkpoints/dp_final.pt\n",
            "\n",
            "--- Training Complete ---\n",
            "Best validation accuracy: 0.8578\n",
            "Final test accuracy: 0.8521\n",
            "Privacy guarantee: (ε=8.00, δ=1e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python mia_evaluation.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtDnaZ3On9Kh",
        "outputId": "54f735f3-2b25-4375-9789-d60f204693e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Loading Data ---\n",
            "Training data already exists at data/adult.data\n",
            "Test data already exists at data/adult.test\n",
            "Training samples after dropping NA: 30162\n",
            "Test samples after dropping NA: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating Baseline Model ---\n",
            "Loading from: checkpoints/baseline_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5107\n",
            "  Accuracy: 0.6444\n",
            "  Advantage: 0.0075\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5107\n",
            "  Accuracy: 0.6444\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/dp_final.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/dp-adult-privacy/src/mia_evaluation.py\", line 322, in <module>\n",
            "    main()\n",
            "  File \"/content/dp-adult-privacy/src/mia_evaluation.py\", line 311, in main\n",
            "    results = run_mia_evaluation(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/dp-adult-privacy/src/mia_evaluation.py\", line 264, in run_mia_evaluation\n",
            "    model = load_model(dp_path, device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/dp-adult-privacy/src/mia_evaluation.py\", line 191, in load_model\n",
            "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1529, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dp-adult-privacy\n",
        "!git pull\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiKKZSz8pqov",
        "outputId": "d8cafc96-f962-46f2-d8aa-92d3fe2e362c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dp-adult-privacy\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (5/5), 1.59 KiB | 407.00 KiB/s, done.\n",
            "From https://github.com/Imomazin/dp-adult-privacy\n",
            "   a7bacc2..3b411e9  main       -> origin/main\n",
            "   7962c28..b0274ea  claude/setup-privacy-learning-research-9a9PQ -> origin/claude/setup-privacy-learning-research-9a9PQ\n",
            "Updating a7bacc2..3b411e9\n",
            "Fast-forward\n",
            " src/mia_evaluation.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dp-adult-privacy/src\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1H4RqJEp_HF",
        "outputId": "61f94f88-bd66-4f08-cb34-03a857021250"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dp-adult-privacy/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python mia_evaluation.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaCFtEiqqCS6",
        "outputId": "861e8f06-0d3d-47ae-9be0-11ab4c9373d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Loading Data ---\n",
            "Training data already exists at data/adult.data\n",
            "Test data already exists at data/adult.test\n",
            "Training samples after dropping NA: 30162\n",
            "Test samples after dropping NA: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating Baseline Model ---\n",
            "Loading from: checkpoints/baseline_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5107\n",
            "  Accuracy: 0.6444\n",
            "  Advantage: 0.0075\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5107\n",
            "  Accuracy: 0.6444\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5019\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5019\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "--- Comparison: Baseline vs DP ---\n",
            "Threshold Attack AUC: 0.5107 -> 0.5019\n",
            "Loss Attack AUC: 0.5107 -> 0.5019\n",
            "Privacy improvement (AUC reduction): 0.0088\n",
            "\n",
            "--- MIA Evaluation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dp-adult-privacy\n",
        "!git pull\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDcyAF955lUB",
        "outputId": "a9254dcd-9d13-4660-a1ae-bf59a61ca211"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dp-adult-privacy\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 13 (delta 7), reused 11 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (13/13), 7.86 KiB | 804.00 KiB/s, done.\n",
            "From https://github.com/Imomazin/dp-adult-privacy\n",
            "   3b411e9..ae2e00f  main       -> origin/main\n",
            "   b0274ea..b9562f4  claude/setup-privacy-learning-research-9a9PQ -> origin/claude/setup-privacy-learning-research-9a9PQ\n",
            "Updating 3b411e9..ae2e00f\n",
            "Fast-forward\n",
            " src/data_loader.py    | 228 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
            " src/mia_evaluation.py |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/run_sweep.py      | 258 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " src/train_baseline.py |  11 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " src/train_dp.py       |  11 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " 5 files changed, 411 insertions(+), 106 deletions(-)\n",
            " create mode 100644 src/run_sweep.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/dp-adult-privacy/src\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4_XmZnH5_HR",
        "outputId": "eb678d4c-e355-4a4a-f5c4-c88194c6c999"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dp-adult-privacy/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_sweep.py --datasets adult bank --epsilons 4 8 --epochs 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umvc_oCn6EHB",
        "outputId": "42ee21cf-4939-4b2a-8982-acc207356023"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DP TRAINING PARAMETER SWEEP\n",
            "============================================================\n",
            "Datasets: ['adult', 'bank']\n",
            "Epsilons: [4.0, 8.0]\n",
            "Epochs: 10\n",
            "Seed: 42\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Dataset: ADULT\n",
            "============================================================\n",
            "\n",
            "[1/6] Training baseline for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Training ---\n",
            "Epoch 1/10 | Train Loss: 0.4007 | Val Loss: 0.3229 | Val Acc: 0.8505\n",
            "Epoch 2/10 | Train Loss: 0.3173 | Val Loss: 0.3179 | Val Acc: 0.8489\n",
            "Epoch 3/10 | Train Loss: 0.3117 | Val Loss: 0.3134 | Val Acc: 0.8542\n",
            "Epoch 4/10 | Train Loss: 0.3099 | Val Loss: 0.3124 | Val Acc: 0.8575\n",
            "Epoch 5/10 | Train Loss: 0.3072 | Val Loss: 0.3107 | Val Acc: 0.8535\n",
            "Epoch 6/10 | Train Loss: 0.3079 | Val Loss: 0.3144 | Val Acc: 0.8575\n",
            "Epoch 7/10 | Train Loss: 0.3017 | Val Loss: 0.3097 | Val Acc: 0.8591\n",
            "Epoch 8/10 | Train Loss: 0.2991 | Val Loss: 0.3112 | Val Acc: 0.8565\n",
            "Epoch 9/10 | Train Loss: 0.2991 | Val Loss: 0.3126 | Val Acc: 0.8535\n",
            "Epoch 10/10 | Train Loss: 0.2968 | Val Loss: 0.3120 | Val Acc: 0.8598\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3194 | Test Accuracy: 0.8511\n",
            "Model saved to checkpoints/adult_baseline/baseline_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating Baseline Model ---\n",
            "Loading from: checkpoints/adult_baseline/baseline_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5065\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0007\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5065\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "[2/6] Training DP (ε=4.0) for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 4.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.7263\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/10 | Train Loss: 0.5681 | Val Loss: 0.4852 | Val Acc: 0.7511 | ε: 2.04\n",
            "Epoch 2/10 | Train Loss: 0.4493 | Val Loss: 0.4111 | Val Acc: 0.8336 | ε: 2.39\n",
            "Epoch 3/10 | Train Loss: 0.4523 | Val Loss: 0.4643 | Val Acc: 0.8445 | ε: 2.66\n",
            "Epoch 4/10 | Train Loss: 0.4702 | Val Loss: 0.4557 | Val Acc: 0.8485 | ε: 2.90\n",
            "Epoch 5/10 | Train Loss: 0.4575 | Val Loss: 0.4628 | Val Acc: 0.8495 | ε: 3.11\n",
            "Epoch 6/10 | Train Loss: 0.4718 | Val Loss: 0.4558 | Val Acc: 0.8469 | ε: 3.31\n",
            "Epoch 7/10 | Train Loss: 0.4750 | Val Loss: 0.4680 | Val Acc: 0.8525 | ε: 3.49\n",
            "Epoch 8/10 | Train Loss: 0.4649 | Val Loss: 0.4729 | Val Acc: 0.8512 | ε: 3.67\n",
            "Epoch 9/10 | Train Loss: 0.4663 | Val Loss: 0.4656 | Val Acc: 0.8542 | ε: 3.84\n",
            "Epoch 10/10 | Train Loss: 0.4816 | Val Loss: 0.4598 | Val Acc: 0.8522 | ε: 4.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (4.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4585 | Test Accuracy: 0.8491\n",
            "Model saved to checkpoints/adult_dp_eps4.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/adult_dp_eps4.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5010\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5010\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "[3/6] Training DP (ε=8.0) for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 8.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.5809\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/10 | Train Loss: 0.5623 | Val Loss: 0.4677 | Val Acc: 0.7511 | ε: 4.11\n",
            "Epoch 2/10 | Train Loss: 0.4373 | Val Loss: 0.4194 | Val Acc: 0.8402 | ε: 4.80\n",
            "Epoch 3/10 | Train Loss: 0.4651 | Val Loss: 0.4689 | Val Acc: 0.8452 | ε: 5.35\n",
            "Epoch 4/10 | Train Loss: 0.4704 | Val Loss: 0.4574 | Val Acc: 0.8492 | ε: 5.82\n",
            "Epoch 5/10 | Train Loss: 0.4563 | Val Loss: 0.4627 | Val Acc: 0.8502 | ε: 6.24\n",
            "Epoch 6/10 | Train Loss: 0.4704 | Val Loss: 0.4547 | Val Acc: 0.8485 | ε: 6.64\n",
            "Epoch 7/10 | Train Loss: 0.4731 | Val Loss: 0.4663 | Val Acc: 0.8525 | ε: 7.00\n",
            "Epoch 8/10 | Train Loss: 0.4607 | Val Loss: 0.4703 | Val Acc: 0.8532 | ε: 7.35\n",
            "Epoch 9/10 | Train Loss: 0.4625 | Val Loss: 0.4637 | Val Acc: 0.8552 | ε: 7.68\n",
            "Epoch 10/10 | Train Loss: 0.4776 | Val Loss: 0.4579 | Val Acc: 0.8525 | ε: 7.99\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (7.99, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4572 | Test Accuracy: 0.8493\n",
            "Model saved to checkpoints/adult_dp_eps8.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/adult_dp_eps8.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5012\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5012\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "============================================================\n",
            "Dataset: BANK\n",
            "============================================================\n",
            "\n",
            "[4/6] Training baseline for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Downloading Bank Marketing data...\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Training ---\n",
            "Epoch 1/10 | Train Loss: 0.2885 | Val Loss: 0.2315 | Val Acc: 0.9010\n",
            "Epoch 2/10 | Train Loss: 0.2175 | Val Loss: 0.2198 | Val Acc: 0.9082\n",
            "Epoch 3/10 | Train Loss: 0.2095 | Val Loss: 0.2149 | Val Acc: 0.9085\n",
            "Epoch 4/10 | Train Loss: 0.2046 | Val Loss: 0.2083 | Val Acc: 0.9049\n",
            "Epoch 5/10 | Train Loss: 0.1996 | Val Loss: 0.2066 | Val Acc: 0.9088\n",
            "Epoch 6/10 | Train Loss: 0.1956 | Val Loss: 0.2057 | Val Acc: 0.9057\n",
            "Epoch 7/10 | Train Loss: 0.1932 | Val Loss: 0.1969 | Val Acc: 0.9124\n",
            "Epoch 8/10 | Train Loss: 0.1911 | Val Loss: 0.1981 | Val Acc: 0.9060\n",
            "Epoch 9/10 | Train Loss: 0.1871 | Val Loss: 0.1933 | Val Acc: 0.9107\n",
            "Epoch 10/10 | Train Loss: 0.1862 | Val Loss: 0.1970 | Val Acc: 0.9090\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.2105 | Test Accuracy: 0.9078\n",
            "Model saved to checkpoints/bank_baseline/baseline_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating Baseline Model ---\n",
            "Loading from: checkpoints/bank_baseline/baseline_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5043\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5043\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "[5/6] Training DP (ε=4.0) for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 4.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.7034\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/10 | Train Loss: 0.4332 | Val Loss: 0.3963 | Val Acc: 0.8831 | ε: 2.08\n",
            "Epoch 2/10 | Train Loss: 0.3666 | Val Loss: 0.3637 | Val Acc: 0.8831 | ε: 2.43\n",
            "Epoch 3/10 | Train Loss: 0.3462 | Val Loss: 0.3446 | Val Acc: 0.8831 | ε: 2.70\n",
            "Epoch 4/10 | Train Loss: 0.3322 | Val Loss: 0.3371 | Val Acc: 0.8831 | ε: 2.93\n",
            "Epoch 5/10 | Train Loss: 0.3194 | Val Loss: 0.3340 | Val Acc: 0.8861 | ε: 3.13\n",
            "Epoch 6/10 | Train Loss: 0.3195 | Val Loss: 0.3303 | Val Acc: 0.8880 | ε: 3.32\n",
            "Epoch 7/10 | Train Loss: 0.3119 | Val Loss: 0.3316 | Val Acc: 0.8925 | ε: 3.50\n",
            "Epoch 8/10 | Train Loss: 0.3140 | Val Loss: 0.3345 | Val Acc: 0.8974 | ε: 3.68\n",
            "Epoch 9/10 | Train Loss: 0.3144 | Val Loss: 0.3458 | Val Acc: 0.8977 | ε: 3.84\n",
            "Epoch 10/10 | Train Loss: 0.3320 | Val Loss: 0.3324 | Val Acc: 0.8991 | ε: 4.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (4.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3209 | Test Accuracy: 0.8996\n",
            "Model saved to checkpoints/bank_dp_eps4.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/bank_dp_eps4.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5018\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5018\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "[6/6] Training DP (ε=8.0) for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 8.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.5664\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/10 | Train Loss: 0.4323 | Val Loss: 0.3897 | Val Acc: 0.8831 | ε: 4.17\n",
            "Epoch 2/10 | Train Loss: 0.3603 | Val Loss: 0.3575 | Val Acc: 0.8831 | ε: 4.85\n",
            "Epoch 3/10 | Train Loss: 0.3401 | Val Loss: 0.3383 | Val Acc: 0.8831 | ε: 5.39\n",
            "Epoch 4/10 | Train Loss: 0.3265 | Val Loss: 0.3313 | Val Acc: 0.8836 | ε: 5.86\n",
            "Epoch 5/10 | Train Loss: 0.3141 | Val Loss: 0.3298 | Val Acc: 0.8878 | ε: 6.27\n",
            "Epoch 6/10 | Train Loss: 0.3156 | Val Loss: 0.3286 | Val Acc: 0.8916 | ε: 6.66\n",
            "Epoch 7/10 | Train Loss: 0.3115 | Val Loss: 0.3367 | Val Acc: 0.8966 | ε: 7.02\n",
            "Epoch 8/10 | Train Loss: 0.3155 | Val Loss: 0.3357 | Val Acc: 0.8999 | ε: 7.36\n",
            "Epoch 9/10 | Train Loss: 0.3153 | Val Loss: 0.3449 | Val Acc: 0.8999 | ε: 7.68\n",
            "Epoch 10/10 | Train Loss: 0.3324 | Val Loss: 0.3303 | Val Acc: 0.9005 | ε: 7.99\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (7.99, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3207 | Test Accuracy: 0.8994\n",
            "Model saved to checkpoints/bank_dp_eps8.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/bank_dp_eps8.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5016\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5016\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "Results saved to results/results.csv\n",
            "\n",
            "================================================================================\n",
            "SWEEP RESULTS SUMMARY\n",
            "================================================================================\n",
            "Dataset    Model        Epsilon    Test Acc     MIA AUC   \n",
            "--------------------------------------------------------------------------------\n",
            "adult      baseline     N/A        0.8511      0.5065\n",
            "adult      dp           4.0        0.8491      0.5010\n",
            "adult      dp           8.0        0.8493      0.5012\n",
            "bank       baseline     N/A        0.9078      0.5043\n",
            "bank       dp           4.0        0.8996      0.5018\n",
            "bank       dp           8.0        0.8994      0.5016\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_sweep.py --datasets adult bank --epsilons 2 4 8 16 --epochs 20 --seed 42\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azU1Rxo97RFO",
        "outputId": "7dac44cf-cca8-48e9-e6ec-31b3be4af2f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DP TRAINING PARAMETER SWEEP\n",
            "============================================================\n",
            "Datasets: ['adult', 'bank']\n",
            "Epsilons: [2.0, 4.0, 8.0, 16.0]\n",
            "Epochs: 20\n",
            "Seed: 42\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Dataset: ADULT\n",
            "============================================================\n",
            "\n",
            "[1/10] Training baseline for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Training ---\n",
            "Epoch 1/20 | Train Loss: 0.4007 | Val Loss: 0.3229 | Val Acc: 0.8505\n",
            "Epoch 2/20 | Train Loss: 0.3173 | Val Loss: 0.3179 | Val Acc: 0.8489\n",
            "Epoch 3/20 | Train Loss: 0.3117 | Val Loss: 0.3134 | Val Acc: 0.8542\n",
            "Epoch 4/20 | Train Loss: 0.3099 | Val Loss: 0.3124 | Val Acc: 0.8575\n",
            "Epoch 5/20 | Train Loss: 0.3072 | Val Loss: 0.3107 | Val Acc: 0.8535\n",
            "Epoch 6/20 | Train Loss: 0.3079 | Val Loss: 0.3144 | Val Acc: 0.8575\n",
            "Epoch 7/20 | Train Loss: 0.3017 | Val Loss: 0.3097 | Val Acc: 0.8591\n",
            "Epoch 8/20 | Train Loss: 0.2991 | Val Loss: 0.3112 | Val Acc: 0.8565\n",
            "Epoch 9/20 | Train Loss: 0.2991 | Val Loss: 0.3126 | Val Acc: 0.8535\n",
            "Epoch 10/20 | Train Loss: 0.2968 | Val Loss: 0.3120 | Val Acc: 0.8598\n",
            "Epoch 11/20 | Train Loss: 0.2932 | Val Loss: 0.3124 | Val Acc: 0.8578\n",
            "Epoch 12/20 | Train Loss: 0.2916 | Val Loss: 0.3094 | Val Acc: 0.8608\n",
            "Epoch 13/20 | Train Loss: 0.2929 | Val Loss: 0.3133 | Val Acc: 0.8585\n",
            "Epoch 14/20 | Train Loss: 0.2905 | Val Loss: 0.3197 | Val Acc: 0.8542\n",
            "Epoch 15/20 | Train Loss: 0.2891 | Val Loss: 0.3127 | Val Acc: 0.8605\n",
            "Epoch 16/20 | Train Loss: 0.2825 | Val Loss: 0.3158 | Val Acc: 0.8578\n",
            "Epoch 17/20 | Train Loss: 0.2833 | Val Loss: 0.3177 | Val Acc: 0.8571\n",
            "Epoch 18/20 | Train Loss: 0.2815 | Val Loss: 0.3224 | Val Acc: 0.8479\n",
            "Epoch 19/20 | Train Loss: 0.2828 | Val Loss: 0.3224 | Val Acc: 0.8495\n",
            "Epoch 20/20 | Train Loss: 0.2751 | Val Loss: 0.3205 | Val Acc: 0.8598\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3336 | Test Accuracy: 0.8487\n",
            "Model saved to checkpoints/adult_baseline/baseline_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating Baseline Model ---\n",
            "Loading from: checkpoints/adult_baseline/baseline_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5107\n",
            "  Accuracy: 0.6444\n",
            "  Advantage: 0.0075\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5107\n",
            "  Accuracy: 0.6444\n",
            "\n",
            "[2/10] Training DP (ε=2.0) for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 2.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 1.1279\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.5767 | Val Loss: 0.5281 | Val Acc: 0.7511 | ε: 0.50\n",
            "Epoch 2/20 | Train Loss: 0.4827 | Val Loss: 0.4391 | Val Acc: 0.8141 | ε: 0.66\n",
            "Epoch 3/20 | Train Loss: 0.4397 | Val Loss: 0.4358 | Val Acc: 0.8353 | ε: 0.79\n",
            "Epoch 4/20 | Train Loss: 0.4555 | Val Loss: 0.4453 | Val Acc: 0.8452 | ε: 0.90\n",
            "Epoch 5/20 | Train Loss: 0.4557 | Val Loss: 0.4610 | Val Acc: 0.8469 | ε: 1.00\n",
            "Epoch 6/20 | Train Loss: 0.4718 | Val Loss: 0.4573 | Val Acc: 0.8465 | ε: 1.09\n",
            "Epoch 7/20 | Train Loss: 0.4759 | Val Loss: 0.4667 | Val Acc: 0.8499 | ε: 1.17\n",
            "Epoch 8/20 | Train Loss: 0.4703 | Val Loss: 0.4738 | Val Acc: 0.8512 | ε: 1.25\n",
            "Epoch 9/20 | Train Loss: 0.4712 | Val Loss: 0.4667 | Val Acc: 0.8502 | ε: 1.33\n",
            "Epoch 10/20 | Train Loss: 0.4890 | Val Loss: 0.4613 | Val Acc: 0.8502 | ε: 1.40\n",
            "Epoch 11/20 | Train Loss: 0.4772 | Val Loss: 0.4707 | Val Acc: 0.8512 | ε: 1.47\n",
            "Epoch 12/20 | Train Loss: 0.4787 | Val Loss: 0.4750 | Val Acc: 0.8525 | ε: 1.54\n",
            "Epoch 13/20 | Train Loss: 0.4726 | Val Loss: 0.4742 | Val Acc: 0.8528 | ε: 1.60\n",
            "Epoch 14/20 | Train Loss: 0.4802 | Val Loss: 0.4778 | Val Acc: 0.8518 | ε: 1.66\n",
            "Epoch 15/20 | Train Loss: 0.4787 | Val Loss: 0.4726 | Val Acc: 0.8532 | ε: 1.72\n",
            "Epoch 16/20 | Train Loss: 0.4705 | Val Loss: 0.4707 | Val Acc: 0.8542 | ε: 1.78\n",
            "Epoch 17/20 | Train Loss: 0.4650 | Val Loss: 0.4690 | Val Acc: 0.8538 | ε: 1.83\n",
            "Epoch 18/20 | Train Loss: 0.4705 | Val Loss: 0.4750 | Val Acc: 0.8548 | ε: 1.89\n",
            "Epoch 19/20 | Train Loss: 0.4862 | Val Loss: 0.4650 | Val Acc: 0.8561 | ε: 1.94\n",
            "Epoch 20/20 | Train Loss: 0.4714 | Val Loss: 0.4648 | Val Acc: 0.8552 | ε: 2.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (2.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4667 | Test Accuracy: 0.8495\n",
            "Model saved to checkpoints/adult_dp_eps2.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/adult_dp_eps2.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5015\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5015\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "[3/10] Training DP (ε=4.0) for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 4.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.8105\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.5707 | Val Loss: 0.4949 | Val Acc: 0.7511 | ε: 1.40\n",
            "Epoch 2/20 | Train Loss: 0.4571 | Val Loss: 0.4154 | Val Acc: 0.8329 | ε: 1.67\n",
            "Epoch 3/20 | Train Loss: 0.4459 | Val Loss: 0.4597 | Val Acc: 0.8416 | ε: 1.88\n",
            "Epoch 4/20 | Train Loss: 0.4689 | Val Loss: 0.4542 | Val Acc: 0.8472 | ε: 2.06\n",
            "Epoch 5/20 | Train Loss: 0.4579 | Val Loss: 0.4628 | Val Acc: 0.8489 | ε: 2.23\n",
            "Epoch 6/20 | Train Loss: 0.4722 | Val Loss: 0.4562 | Val Acc: 0.8469 | ε: 2.38\n",
            "Epoch 7/20 | Train Loss: 0.4755 | Val Loss: 0.4682 | Val Acc: 0.8508 | ε: 2.53\n",
            "Epoch 8/20 | Train Loss: 0.4665 | Val Loss: 0.4734 | Val Acc: 0.8512 | ε: 2.67\n",
            "Epoch 9/20 | Train Loss: 0.4677 | Val Loss: 0.4660 | Val Acc: 0.8535 | ε: 2.80\n",
            "Epoch 10/20 | Train Loss: 0.4834 | Val Loss: 0.4602 | Val Acc: 0.8525 | ε: 2.92\n",
            "Epoch 11/20 | Train Loss: 0.4721 | Val Loss: 0.4673 | Val Acc: 0.8538 | ε: 3.04\n",
            "Epoch 12/20 | Train Loss: 0.4732 | Val Loss: 0.4712 | Val Acc: 0.8555 | ε: 3.16\n",
            "Epoch 13/20 | Train Loss: 0.4660 | Val Loss: 0.4692 | Val Acc: 0.8548 | ε: 3.28\n",
            "Epoch 14/20 | Train Loss: 0.4723 | Val Loss: 0.4721 | Val Acc: 0.8552 | ε: 3.39\n",
            "Epoch 15/20 | Train Loss: 0.4715 | Val Loss: 0.4658 | Val Acc: 0.8558 | ε: 3.50\n",
            "Epoch 16/20 | Train Loss: 0.4731 | Val Loss: 0.4692 | Val Acc: 0.8542 | ε: 3.60\n",
            "Epoch 17/20 | Train Loss: 0.4629 | Val Loss: 0.4667 | Val Acc: 0.8532 | ε: 3.70\n",
            "Epoch 18/20 | Train Loss: 0.4686 | Val Loss: 0.4691 | Val Acc: 0.8542 | ε: 3.80\n",
            "Epoch 19/20 | Train Loss: 0.4820 | Val Loss: 0.4600 | Val Acc: 0.8552 | ε: 3.90\n",
            "Epoch 20/20 | Train Loss: 0.4680 | Val Loss: 0.4605 | Val Acc: 0.8528 | ε: 4.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (4.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4631 | Test Accuracy: 0.8511\n",
            "Model saved to checkpoints/adult_dp_eps4.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/adult_dp_eps4.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5018\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5018\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "[4/10] Training DP (ε=8.0) for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 8.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.6363\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.5647 | Val Loss: 0.4745 | Val Acc: 0.7511 | ε: 3.12\n",
            "Epoch 2/20 | Train Loss: 0.4414 | Val Loss: 0.4134 | Val Acc: 0.8386 | ε: 3.63\n",
            "Epoch 3/20 | Train Loss: 0.4603 | Val Loss: 0.4677 | Val Acc: 0.8439 | ε: 4.03\n",
            "Epoch 4/20 | Train Loss: 0.4706 | Val Loss: 0.4568 | Val Acc: 0.8492 | ε: 4.38\n",
            "Epoch 5/20 | Train Loss: 0.4568 | Val Loss: 0.4626 | Val Acc: 0.8502 | ε: 4.69\n",
            "Epoch 6/20 | Train Loss: 0.4710 | Val Loss: 0.4551 | Val Acc: 0.8472 | ε: 4.98\n",
            "Epoch 7/20 | Train Loss: 0.4740 | Val Loss: 0.4672 | Val Acc: 0.8528 | ε: 5.25\n",
            "Epoch 8/20 | Train Loss: 0.4625 | Val Loss: 0.4713 | Val Acc: 0.8528 | ε: 5.51\n",
            "Epoch 9/20 | Train Loss: 0.4641 | Val Loss: 0.4644 | Val Acc: 0.8542 | ε: 5.75\n",
            "Epoch 10/20 | Train Loss: 0.4792 | Val Loss: 0.4589 | Val Acc: 0.8522 | ε: 5.99\n",
            "Epoch 11/20 | Train Loss: 0.4685 | Val Loss: 0.4642 | Val Acc: 0.8548 | ε: 6.22\n",
            "Epoch 12/20 | Train Loss: 0.4729 | Val Loss: 0.4680 | Val Acc: 0.8552 | ε: 6.43\n",
            "Epoch 13/20 | Train Loss: 0.4651 | Val Loss: 0.4662 | Val Acc: 0.8552 | ε: 6.65\n",
            "Epoch 14/20 | Train Loss: 0.4680 | Val Loss: 0.4688 | Val Acc: 0.8575 | ε: 6.85\n",
            "Epoch 15/20 | Train Loss: 0.4682 | Val Loss: 0.4635 | Val Acc: 0.8555 | ε: 7.06\n",
            "Epoch 16/20 | Train Loss: 0.4711 | Val Loss: 0.4700 | Val Acc: 0.8542 | ε: 7.25\n",
            "Epoch 17/20 | Train Loss: 0.4611 | Val Loss: 0.4671 | Val Acc: 0.8561 | ε: 7.44\n",
            "Epoch 18/20 | Train Loss: 0.4669 | Val Loss: 0.4672 | Val Acc: 0.8552 | ε: 7.63\n",
            "Epoch 19/20 | Train Loss: 0.4800 | Val Loss: 0.4592 | Val Acc: 0.8578 | ε: 7.82\n",
            "Epoch 20/20 | Train Loss: 0.4666 | Val Loss: 0.4609 | Val Acc: 0.8568 | ε: 8.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (8.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4700 | Test Accuracy: 0.8521\n",
            "Model saved to checkpoints/adult_dp_eps8.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/adult_dp_eps8.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5019\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5019\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "[5/10] Training DP (ε=16.0) for adult...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 30,081\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 16.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.5144\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.5590 | Val Loss: 0.4594 | Val Acc: 0.7551 | ε: 5.86\n",
            "Epoch 2/20 | Train Loss: 0.4339 | Val Loss: 0.4296 | Val Acc: 0.8422 | ε: 6.94\n",
            "Epoch 3/20 | Train Loss: 0.4697 | Val Loss: 0.4694 | Val Acc: 0.8462 | ε: 7.79\n",
            "Epoch 4/20 | Train Loss: 0.4699 | Val Loss: 0.4578 | Val Acc: 0.8505 | ε: 8.52\n",
            "Epoch 5/20 | Train Loss: 0.4552 | Val Loss: 0.4626 | Val Acc: 0.8499 | ε: 9.18\n",
            "Epoch 6/20 | Train Loss: 0.4694 | Val Loss: 0.4541 | Val Acc: 0.8482 | ε: 9.78\n",
            "Epoch 7/20 | Train Loss: 0.4718 | Val Loss: 0.4646 | Val Acc: 0.8538 | ε: 10.34\n",
            "Epoch 8/20 | Train Loss: 0.4583 | Val Loss: 0.4688 | Val Acc: 0.8535 | ε: 10.87\n",
            "Epoch 9/20 | Train Loss: 0.4606 | Val Loss: 0.4627 | Val Acc: 0.8555 | ε: 11.37\n",
            "Epoch 10/20 | Train Loss: 0.4752 | Val Loss: 0.4561 | Val Acc: 0.8532 | ε: 11.86\n",
            "Epoch 11/20 | Train Loss: 0.4674 | Val Loss: 0.4619 | Val Acc: 0.8545 | ε: 12.33\n",
            "Epoch 12/20 | Train Loss: 0.4702 | Val Loss: 0.4656 | Val Acc: 0.8568 | ε: 12.78\n",
            "Epoch 13/20 | Train Loss: 0.4621 | Val Loss: 0.4640 | Val Acc: 0.8535 | ε: 13.21\n",
            "Epoch 14/20 | Train Loss: 0.4645 | Val Loss: 0.4659 | Val Acc: 0.8588 | ε: 13.64\n",
            "Epoch 15/20 | Train Loss: 0.4646 | Val Loss: 0.4612 | Val Acc: 0.8558 | ε: 14.05\n",
            "Epoch 16/20 | Train Loss: 0.4685 | Val Loss: 0.4687 | Val Acc: 0.8545 | ε: 14.46\n",
            "Epoch 17/20 | Train Loss: 0.4584 | Val Loss: 0.4663 | Val Acc: 0.8578 | ε: 14.85\n",
            "Epoch 18/20 | Train Loss: 0.4645 | Val Loss: 0.4652 | Val Acc: 0.8571 | ε: 15.24\n",
            "Epoch 19/20 | Train Loss: 0.4780 | Val Loss: 0.4578 | Val Acc: 0.8588 | ε: 15.62\n",
            "Epoch 20/20 | Train Loss: 0.4642 | Val Loss: 0.4604 | Val Acc: 0.8585 | ε: 15.99\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (15.99, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.4706 | Test Accuracy: 0.8521\n",
            "Model saved to checkpoints/adult_dp_eps16.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (adult) ---\n",
            "Adult dataset - Train: 30162, Test: 15060\n",
            "Feature dimension: 104\n",
            "Train batches: 107, Val batches: 12, Test batches: 59\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/adult_dp_eps16.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5020\n",
            "  Accuracy: 0.6432\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5020\n",
            "  Accuracy: 0.6432\n",
            "\n",
            "============================================================\n",
            "Dataset: BANK\n",
            "============================================================\n",
            "\n",
            "[6/10] Training baseline for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Training ---\n",
            "Epoch 1/20 | Train Loss: 0.2885 | Val Loss: 0.2315 | Val Acc: 0.9010\n",
            "Epoch 2/20 | Train Loss: 0.2175 | Val Loss: 0.2198 | Val Acc: 0.9082\n",
            "Epoch 3/20 | Train Loss: 0.2095 | Val Loss: 0.2149 | Val Acc: 0.9085\n",
            "Epoch 4/20 | Train Loss: 0.2046 | Val Loss: 0.2083 | Val Acc: 0.9049\n",
            "Epoch 5/20 | Train Loss: 0.1996 | Val Loss: 0.2066 | Val Acc: 0.9088\n",
            "Epoch 6/20 | Train Loss: 0.1956 | Val Loss: 0.2057 | Val Acc: 0.9057\n",
            "Epoch 7/20 | Train Loss: 0.1932 | Val Loss: 0.1969 | Val Acc: 0.9124\n",
            "Epoch 8/20 | Train Loss: 0.1911 | Val Loss: 0.1981 | Val Acc: 0.9060\n",
            "Epoch 9/20 | Train Loss: 0.1871 | Val Loss: 0.1933 | Val Acc: 0.9107\n",
            "Epoch 10/20 | Train Loss: 0.1862 | Val Loss: 0.1970 | Val Acc: 0.9090\n",
            "Epoch 11/20 | Train Loss: 0.1848 | Val Loss: 0.1931 | Val Acc: 0.9093\n",
            "Epoch 12/20 | Train Loss: 0.1806 | Val Loss: 0.1974 | Val Acc: 0.9082\n",
            "Epoch 13/20 | Train Loss: 0.1789 | Val Loss: 0.1933 | Val Acc: 0.9115\n",
            "Epoch 14/20 | Train Loss: 0.1775 | Val Loss: 0.1952 | Val Acc: 0.9074\n",
            "Epoch 15/20 | Train Loss: 0.1775 | Val Loss: 0.1903 | Val Acc: 0.9110\n",
            "Epoch 16/20 | Train Loss: 0.1745 | Val Loss: 0.1924 | Val Acc: 0.9129\n",
            "Epoch 17/20 | Train Loss: 0.1724 | Val Loss: 0.1891 | Val Acc: 0.9132\n",
            "Epoch 18/20 | Train Loss: 0.1704 | Val Loss: 0.1911 | Val Acc: 0.9121\n",
            "Epoch 19/20 | Train Loss: 0.1681 | Val Loss: 0.1922 | Val Acc: 0.9129\n",
            "Epoch 20/20 | Train Loss: 0.1663 | Val Loss: 0.1945 | Val Acc: 0.9132\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.2203 | Test Accuracy: 0.9090\n",
            "Model saved to checkpoints/bank_baseline/baseline_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating Baseline Model ---\n",
            "Loading from: checkpoints/bank_baseline/baseline_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5050\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0034\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5050\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "[7/10] Training DP (ε=2.0) for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 2.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 1.0645\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.4341 | Val Loss: 0.4100 | Val Acc: 0.8831 | ε: 0.51\n",
            "Epoch 2/20 | Train Loss: 0.3796 | Val Loss: 0.3767 | Val Acc: 0.8831 | ε: 0.67\n",
            "Epoch 3/20 | Train Loss: 0.3589 | Val Loss: 0.3576 | Val Acc: 0.8831 | ε: 0.80\n",
            "Epoch 4/20 | Train Loss: 0.3441 | Val Loss: 0.3487 | Val Acc: 0.8831 | ε: 0.91\n",
            "Epoch 5/20 | Train Loss: 0.3300 | Val Loss: 0.3433 | Val Acc: 0.8836 | ε: 1.00\n",
            "Epoch 6/20 | Train Loss: 0.3287 | Val Loss: 0.3385 | Val Acc: 0.8850 | ε: 1.09\n",
            "Epoch 7/20 | Train Loss: 0.3206 | Val Loss: 0.3337 | Val Acc: 0.8850 | ε: 1.18\n",
            "Epoch 8/20 | Train Loss: 0.3173 | Val Loss: 0.3325 | Val Acc: 0.8889 | ε: 1.26\n",
            "Epoch 9/20 | Train Loss: 0.3137 | Val Loss: 0.3416 | Val Acc: 0.8916 | ε: 1.33\n",
            "Epoch 10/20 | Train Loss: 0.3292 | Val Loss: 0.3312 | Val Acc: 0.8936 | ε: 1.40\n",
            "Epoch 11/20 | Train Loss: 0.3202 | Val Loss: 0.3403 | Val Acc: 0.8944 | ε: 1.47\n",
            "Epoch 12/20 | Train Loss: 0.3239 | Val Loss: 0.3438 | Val Acc: 0.8974 | ε: 1.54\n",
            "Epoch 13/20 | Train Loss: 0.3162 | Val Loss: 0.3445 | Val Acc: 0.8983 | ε: 1.60\n",
            "Epoch 14/20 | Train Loss: 0.3188 | Val Loss: 0.3401 | Val Acc: 0.8999 | ε: 1.66\n",
            "Epoch 15/20 | Train Loss: 0.3287 | Val Loss: 0.3460 | Val Acc: 0.9007 | ε: 1.72\n",
            "Epoch 16/20 | Train Loss: 0.3213 | Val Loss: 0.3510 | Val Acc: 0.9010 | ε: 1.78\n",
            "Epoch 17/20 | Train Loss: 0.3139 | Val Loss: 0.3433 | Val Acc: 0.8999 | ε: 1.83\n",
            "Epoch 18/20 | Train Loss: 0.3164 | Val Loss: 0.3535 | Val Acc: 0.9005 | ε: 1.89\n",
            "Epoch 19/20 | Train Loss: 0.3374 | Val Loss: 0.3429 | Val Acc: 0.9021 | ε: 1.94\n",
            "Epoch 20/20 | Train Loss: 0.3215 | Val Loss: 0.3546 | Val Acc: 0.9021 | ε: 1.99\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (1.99, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3467 | Test Accuracy: 0.9003\n",
            "Model saved to checkpoints/bank_dp_eps2.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/bank_dp_eps2.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5012\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5012\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "[8/10] Training DP (ε=4.0) for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 4.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.7788\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.4336 | Val Loss: 0.3996 | Val Acc: 0.8831 | ε: 1.45\n",
            "Epoch 2/20 | Train Loss: 0.3697 | Val Loss: 0.3668 | Val Acc: 0.8831 | ε: 1.72\n",
            "Epoch 3/20 | Train Loss: 0.3492 | Val Loss: 0.3476 | Val Acc: 0.8831 | ε: 1.93\n",
            "Epoch 4/20 | Train Loss: 0.3349 | Val Loss: 0.3398 | Val Acc: 0.8831 | ε: 2.11\n",
            "Epoch 5/20 | Train Loss: 0.3219 | Val Loss: 0.3363 | Val Acc: 0.8855 | ε: 2.27\n",
            "Epoch 6/20 | Train Loss: 0.3217 | Val Loss: 0.3320 | Val Acc: 0.8861 | ε: 2.42\n",
            "Epoch 7/20 | Train Loss: 0.3134 | Val Loss: 0.3304 | Val Acc: 0.8908 | ε: 2.56\n",
            "Epoch 8/20 | Train Loss: 0.3137 | Val Loss: 0.3330 | Val Acc: 0.8941 | ε: 2.70\n",
            "Epoch 9/20 | Train Loss: 0.3137 | Val Loss: 0.3453 | Val Acc: 0.8958 | ε: 2.82\n",
            "Epoch 10/20 | Train Loss: 0.3313 | Val Loss: 0.3327 | Val Acc: 0.8977 | ε: 2.95\n",
            "Epoch 11/20 | Train Loss: 0.3213 | Val Loss: 0.3415 | Val Acc: 0.8994 | ε: 3.06\n",
            "Epoch 12/20 | Train Loss: 0.3246 | Val Loss: 0.3423 | Val Acc: 0.9013 | ε: 3.18\n",
            "Epoch 13/20 | Train Loss: 0.3167 | Val Loss: 0.3446 | Val Acc: 0.9016 | ε: 3.29\n",
            "Epoch 14/20 | Train Loss: 0.3199 | Val Loss: 0.3427 | Val Acc: 0.9013 | ε: 3.40\n",
            "Epoch 15/20 | Train Loss: 0.3310 | Val Loss: 0.3456 | Val Acc: 0.9027 | ε: 3.51\n",
            "Epoch 16/20 | Train Loss: 0.3251 | Val Loss: 0.3502 | Val Acc: 0.9027 | ε: 3.61\n",
            "Epoch 17/20 | Train Loss: 0.3175 | Val Loss: 0.3480 | Val Acc: 0.9007 | ε: 3.71\n",
            "Epoch 18/20 | Train Loss: 0.3196 | Val Loss: 0.3564 | Val Acc: 0.9013 | ε: 3.81\n",
            "Epoch 19/20 | Train Loss: 0.3398 | Val Loss: 0.3423 | Val Acc: 0.9021 | ε: 3.90\n",
            "Epoch 20/20 | Train Loss: 0.3245 | Val Loss: 0.3515 | Val Acc: 0.9024 | ε: 4.00\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (4.00, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3472 | Test Accuracy: 0.9007\n",
            "Model saved to checkpoints/bank_dp_eps4.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/bank_dp_eps4.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5010\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5010\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "[9/10] Training DP (ε=8.0) for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 8.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.6180\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.4327 | Val Loss: 0.3923 | Val Acc: 0.8831 | ε: 3.19\n",
            "Epoch 2/20 | Train Loss: 0.3628 | Val Loss: 0.3599 | Val Acc: 0.8831 | ε: 3.70\n",
            "Epoch 3/20 | Train Loss: 0.3425 | Val Loss: 0.3408 | Val Acc: 0.8831 | ε: 4.09\n",
            "Epoch 4/20 | Train Loss: 0.3288 | Val Loss: 0.3336 | Val Acc: 0.8828 | ε: 4.43\n",
            "Epoch 5/20 | Train Loss: 0.3162 | Val Loss: 0.3313 | Val Acc: 0.8847 | ε: 4.74\n",
            "Epoch 6/20 | Train Loss: 0.3170 | Val Loss: 0.3287 | Val Acc: 0.8908 | ε: 5.03\n",
            "Epoch 7/20 | Train Loss: 0.3112 | Val Loss: 0.3346 | Val Acc: 0.8949 | ε: 5.29\n",
            "Epoch 8/20 | Train Loss: 0.3149 | Val Loss: 0.3356 | Val Acc: 0.8996 | ε: 5.54\n",
            "Epoch 9/20 | Train Loss: 0.3150 | Val Loss: 0.3455 | Val Acc: 0.8988 | ε: 5.79\n",
            "Epoch 10/20 | Train Loss: 0.3323 | Val Loss: 0.3312 | Val Acc: 0.9002 | ε: 6.02\n",
            "Epoch 11/20 | Train Loss: 0.3223 | Val Loss: 0.3402 | Val Acc: 0.9007 | ε: 6.24\n",
            "Epoch 12/20 | Train Loss: 0.3251 | Val Loss: 0.3410 | Val Acc: 0.9021 | ε: 6.45\n",
            "Epoch 13/20 | Train Loss: 0.3184 | Val Loss: 0.3449 | Val Acc: 0.9019 | ε: 6.66\n",
            "Epoch 14/20 | Train Loss: 0.3218 | Val Loss: 0.3437 | Val Acc: 0.9024 | ε: 6.87\n",
            "Epoch 15/20 | Train Loss: 0.3328 | Val Loss: 0.3451 | Val Acc: 0.9021 | ε: 7.06\n",
            "Epoch 16/20 | Train Loss: 0.3275 | Val Loss: 0.3484 | Val Acc: 0.9021 | ε: 7.26\n",
            "Epoch 17/20 | Train Loss: 0.3194 | Val Loss: 0.3499 | Val Acc: 0.9013 | ε: 7.45\n",
            "Epoch 18/20 | Train Loss: 0.3203 | Val Loss: 0.3567 | Val Acc: 0.9016 | ε: 7.63\n",
            "Epoch 19/20 | Train Loss: 0.3396 | Val Loss: 0.3406 | Val Acc: 0.9021 | ε: 7.81\n",
            "Epoch 20/20 | Train Loss: 0.3240 | Val Loss: 0.3466 | Val Acc: 0.9024 | ε: 7.99\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (7.99, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3443 | Test Accuracy: 0.9012\n",
            "Model saved to checkpoints/bank_dp_eps8.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/bank_dp_eps8.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5011\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5011\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "[10/10] Training DP (ε=16.0) for bank...\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Creating Model ---\n",
            "Model parameters: 23,297\n",
            "\n",
            "--- Setting up Differential Privacy ---\n",
            "Target epsilon: 16.0\n",
            "Target delta: 1e-05\n",
            "Max gradient norm: 1.0\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "Using noise multiplier: 0.5025\n",
            "\n",
            "--- Training with DP-SGD ---\n",
            "/content/dp-adult-privacy/src/train_dp.py:62: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n",
            "Epoch 1/20 | Train Loss: 0.4316 | Val Loss: 0.3864 | Val Acc: 0.8831 | ε: 5.94\n",
            "Epoch 2/20 | Train Loss: 0.3570 | Val Loss: 0.3542 | Val Acc: 0.8831 | ε: 7.02\n",
            "Epoch 3/20 | Train Loss: 0.3369 | Val Loss: 0.3350 | Val Acc: 0.8831 | ε: 7.86\n",
            "Epoch 4/20 | Train Loss: 0.3236 | Val Loss: 0.3281 | Val Acc: 0.8855 | ε: 8.59\n",
            "Epoch 5/20 | Train Loss: 0.3113 | Val Loss: 0.3280 | Val Acc: 0.8900 | ε: 9.24\n",
            "Epoch 6/20 | Train Loss: 0.3146 | Val Loss: 0.3298 | Val Acc: 0.8933 | ε: 9.83\n",
            "Epoch 7/20 | Train Loss: 0.3125 | Val Loss: 0.3397 | Val Acc: 0.8980 | ε: 10.39\n",
            "Epoch 8/20 | Train Loss: 0.3161 | Val Loss: 0.3357 | Val Acc: 0.9021 | ε: 10.92\n",
            "Epoch 9/20 | Train Loss: 0.3157 | Val Loss: 0.3445 | Val Acc: 0.9002 | ε: 11.42\n",
            "Epoch 10/20 | Train Loss: 0.3327 | Val Loss: 0.3295 | Val Acc: 0.9002 | ε: 11.90\n",
            "Epoch 11/20 | Train Loss: 0.3240 | Val Loss: 0.3392 | Val Acc: 0.9005 | ε: 12.36\n",
            "Epoch 12/20 | Train Loss: 0.3256 | Val Loss: 0.3401 | Val Acc: 0.9027 | ε: 12.81\n",
            "Epoch 13/20 | Train Loss: 0.3194 | Val Loss: 0.3439 | Val Acc: 0.9010 | ε: 13.24\n",
            "Epoch 14/20 | Train Loss: 0.3225 | Val Loss: 0.3432 | Val Acc: 0.9024 | ε: 13.66\n",
            "Epoch 15/20 | Train Loss: 0.3326 | Val Loss: 0.3425 | Val Acc: 0.9032 | ε: 14.07\n",
            "Epoch 16/20 | Train Loss: 0.3267 | Val Loss: 0.3442 | Val Acc: 0.9013 | ε: 14.47\n",
            "Epoch 17/20 | Train Loss: 0.3180 | Val Loss: 0.3483 | Val Acc: 0.9024 | ε: 14.86\n",
            "Epoch 18/20 | Train Loss: 0.3180 | Val Loss: 0.3543 | Val Acc: 0.9019 | ε: 15.25\n",
            "Epoch 19/20 | Train Loss: 0.3365 | Val Loss: 0.3374 | Val Acc: 0.9032 | ε: 15.62\n",
            "Epoch 20/20 | Train Loss: 0.3208 | Val Loss: 0.3425 | Val Acc: 0.9030 | ε: 15.99\n",
            "\n",
            "--- Final Privacy Guarantee ---\n",
            "(ε, δ)-DP: (15.99, 1e-05)\n",
            "\n",
            "--- Final Test Evaluation ---\n",
            "Test Loss: 0.3406 | Test Accuracy: 0.9018\n",
            "Model saved to checkpoints/bank_dp_eps16.0/dp_final.pt\n",
            "Using device: cpu\n",
            "\n",
            "--- Loading Data (bank) ---\n",
            "Bank dataset - Total samples: 45211\n",
            "Bank dataset - Train: 36168, Test: 9043\n",
            "Feature dimension: 51\n",
            "Train batches: 128, Val batches: 15, Test batches: 36\n",
            "\n",
            "--- Evaluating DP Model ---\n",
            "Loading from: checkpoints/bank_dp_eps16.0/dp_final.pt\n",
            "\n",
            "Threshold Attack:\n",
            "  AUC: 0.5012\n",
            "  Accuracy: 0.7826\n",
            "  Advantage: 0.0000\n",
            "\n",
            "Loss Attack:\n",
            "  AUC: 0.5012\n",
            "  Accuracy: 0.7826\n",
            "\n",
            "Results saved to results/results.csv\n",
            "\n",
            "================================================================================\n",
            "SWEEP RESULTS SUMMARY\n",
            "================================================================================\n",
            "Dataset    Model        Epsilon    Test Acc     MIA AUC   \n",
            "--------------------------------------------------------------------------------\n",
            "adult      baseline     N/A        0.8487      0.5107\n",
            "adult      dp           2.0        0.8495      0.5015\n",
            "adult      dp           4.0        0.8511      0.5018\n",
            "adult      dp           8.0        0.8521      0.5019\n",
            "adult      dp           16.0       0.8521      0.5020\n",
            "bank       baseline     N/A        0.9090      0.5050\n",
            "bank       dp           2.0        0.9003      0.5012\n",
            "bank       dp           4.0        0.9007      0.5010\n",
            "bank       dp           8.0        0.9012      0.5011\n",
            "bank       dp           16.0       0.9018      0.5012\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}